{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTA Demo Version\n",
    "This demo version is for tutorial purpose. Here we analyzed only one file of PT_S38417 for 0.78V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repositories\n",
    "All the necessary codes have been developed in different files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n",
      "Number of GPU 1\n",
      "GPU type TITAN RTX\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "Running on the GPU\n",
      "Number of GPU 1\n",
      "GPU type TITAN RTX\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Customized Libraries\n",
    "import configure as config # For model configuration\n",
    "import data_collector # For data processing\n",
    "import model # Model has been developed here\n",
    "import run_model # Model training related code\n",
    "import predict_from_chkpnt # Testing related code\n",
    "import utility # Any other necessary functions for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation and Preparation:\n",
    "We used Synopsys IC Compiler (ICC) for the physical design of benchmarks in 32nm technology available under Synopsys educational license. We used the ICC timing report to extract a set of timing paths and queried ICC to extract the gate and net properties. We used one-hot encoding to represent the value of non-numerical gate properties, such as \"gate type‚Äù or \"threshold voltage‚Äù. Synopsys Primetime was then launched for path-based timing analysis, and the delay of each subpath (ùëÉùê∑ , ùëÉùê∂, and ùëÉùêø) was collected as labels and sub-labels for each timing path, respectively.\n",
    "\n",
    "Raw data is in json format. We formatted and converted the data in pickle format. The necessary functions are in the \"data_collector.py\" file. So, we import that here at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " starting file processing v_0.78\n",
      "file_processed v_0.78\n",
      "preprocess_data v_0.78, file processing time 1.654989300000011, preprocessing_data 6.4872025000000235\n",
      " starting file processing v_0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tchowdh6\\Documents\\RAPTA\\RAPTA\\main\\data_collector.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_arr = np.array(X)\n",
      "C:\\Users\\tchowdh6\\Documents\\RAPTA\\RAPTA\\main\\data_collector.py:132: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_new = np.array(X_new) # l, d, c, VS, sublabel, label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess_data v_0.78\n"
     ]
    }
   ],
   "source": [
    "fp=config.fp[0:-1]\n",
    "raw_input_file = config.processed_saved_path + fp + '/jason.json'\n",
    "processed_saved_path = config.processed_saved_path + fp + '/'\n",
    "processed_file = config.processed_saved_path + fp + '/processed.json'\n",
    "print(' starting file processing {}'.format(fp))\n",
    "file_processing_tic = time.perf_counter()\n",
    "data_collector.file_processing(raw_input_file, processed_file)\n",
    "file_processing_toc = time.perf_counter()\n",
    "print('file_processed {}'.format(fp))\n",
    "data_collector.preprocess_data(processed_file, processed_saved_path, fp)\n",
    "preprocess_data_toc = time.perf_counter()\n",
    "print('preprocess_data {}, file processing time {}, preprocessing_data {}'.format(fp, (\n",
    "            file_processing_toc - file_processing_tic), (preprocess_data_toc - file_processing_tic)))\n",
    "X = pickle.load(open(config.exp_data_path + fp + '_X_gate.pk', 'rb'))\n",
    "X_sublabel = pickle.load(open(config.exp_data_path + fp + '_X_sublabels.pk', 'rb'))\n",
    "Y = pickle.load(open(config.exp_data_path + fp + '_Y_gate.pk', 'rb'))\n",
    "saving_Path_Train = config.exp_data_path + fp + '_train.pk'\n",
    "saving_Path_Test = config.exp_data_path + fp + '_test.pk'\n",
    "print(' starting file processing {}'.format(fp))\n",
    "data_collector.createFromProcessed(X, X_sublabel, Y, saving_Path_Train, saving_Path_Test)\n",
    "print('preprocess_data {}'.format(fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/model_purpose/PT_S38417/v_0.78_train.pk\n",
      "3324\n",
      "Running Main for v_0.78_\n",
      "Running tensormaker\n",
      "Train Input Data Fit Transformed\n",
      "Train Target Data Fit Transformed\n",
      "Running tensormaker\n",
      "Test Input Data Transformed\n",
      "Test Target Data Transformed\n",
      "Iteration: 0/10  Current Loss: 0.4175781309604645 and previously recorded Min Loss None\n",
      "Iteration: 0/20  Current Loss: 0.14063580334186554 and previously recorded Min Loss 0.4175781309604645\n",
      " Model saved\n",
      "Iteration: 1/30  Current Loss: 0.04742218926548958 and previously recorded Min Loss 0.14063580334186554\n",
      " Model saved\n",
      "Iteration: 1/40  Current Loss: 0.02558441273868084 and previously recorded Min Loss 0.04742218926548958\n",
      " Model saved\n",
      "Iteration: 1/50  Current Loss: 0.015926282852888107 and previously recorded Min Loss 0.02558441273868084\n",
      " Model saved\n",
      "Iteration: 2/60  Current Loss: 0.014173892326653004 and previously recorded Min Loss 0.015926282852888107\n",
      " Model saved\n",
      "Iteration: 2/70  Current Loss: 0.010207568295300007 and previously recorded Min Loss 0.014173892326653004\n",
      " Model saved\n",
      "Iteration: 3/80  Current Loss: 0.008568796329200268 and previously recorded Min Loss 0.010207568295300007\n",
      " Model saved\n",
      "Iteration: 3/90  Current Loss: 0.007764830719679594 and previously recorded Min Loss 0.008568796329200268\n",
      " Model saved\n",
      "Iteration: 3/100  Current Loss: 0.006550938356667757 and previously recorded Min Loss 0.007764830719679594\n",
      " Model saved\n",
      "Iteration: 4/110  Current Loss: 0.006210850551724434 and previously recorded Min Loss 0.006550938356667757\n",
      " Model saved\n",
      "Iteration: 4/120  Current Loss: 0.005910962820053101 and previously recorded Min Loss 0.006210850551724434\n",
      " Model saved\n",
      "Iteration: 5/130  Current Loss: 0.005429373588413 and previously recorded Min Loss 0.005910962820053101\n",
      " Model saved\n",
      "Iteration: 5/140  Current Loss: 0.0052455151453614235 and previously recorded Min Loss 0.005429373588413\n",
      " Model saved\n",
      "Iteration: 5/150  Current Loss: 0.004589888732880354 and previously recorded Min Loss 0.0052455151453614235\n",
      " Model saved\n",
      "Iteration: 6/160  Current Loss: 0.0050714523531496525 and previously recorded Min Loss 0.004589888732880354\n",
      "Iteration: 6/170  Current Loss: 0.004124861676245928 and previously recorded Min Loss 0.004589888732880354\n",
      " Model saved\n",
      "Iteration: 7/180  Current Loss: 0.00405711168423295 and previously recorded Min Loss 0.004124861676245928\n",
      " Model saved\n",
      "Iteration: 7/190  Current Loss: 0.003941507078707218 and previously recorded Min Loss 0.00405711168423295\n",
      " Model saved\n",
      "Iteration: 7/200  Current Loss: 0.003637816524133086 and previously recorded Min Loss 0.003941507078707218\n",
      " Model saved\n",
      "Iteration: 8/210  Current Loss: 0.003956260625272989 and previously recorded Min Loss 0.003637816524133086\n",
      "Iteration: 8/220  Current Loss: 0.00509829493239522 and previously recorded Min Loss 0.003637816524133086\n",
      "Iteration: 9/230  Current Loss: 0.0037986417300999165 and previously recorded Min Loss 0.003637816524133086\n",
      "Iteration: 9/240  Current Loss: 0.003073514671996236 and previously recorded Min Loss 0.003637816524133086\n",
      " Model saved\n",
      "Iteration: 9/250  Current Loss: 0.0031126718968153 and previously recorded Min Loss 0.003073514671996236\n",
      "Iteration: 10/260  Current Loss: 0.0029473532922565937 and previously recorded Min Loss 0.003073514671996236\n",
      " Model saved\n",
      "Iteration: 10/270  Current Loss: 0.0028925605583935976 and previously recorded Min Loss 0.0029473532922565937\n",
      " Model saved\n",
      "Iteration: 11/280  Current Loss: 0.003016614355146885 and previously recorded Min Loss 0.0028925605583935976\n",
      "Iteration: 11/290  Current Loss: 0.0027640655171126127 and previously recorded Min Loss 0.0028925605583935976\n",
      " Model saved\n",
      "Iteration: 11/300  Current Loss: 0.0026227841153740883 and previously recorded Min Loss 0.0027640655171126127\n",
      " Model saved\n",
      "Iteration: 12/310  Current Loss: 0.0024746486451476812 and previously recorded Min Loss 0.0026227841153740883\n",
      " Model saved\n",
      "Iteration: 12/320  Current Loss: 0.002871879143640399 and previously recorded Min Loss 0.0024746486451476812\n",
      "Iteration: 13/330  Current Loss: 0.002886418718844652 and previously recorded Min Loss 0.0024746486451476812\n",
      "Iteration: 13/340  Current Loss: 0.0027088054921478033 and previously recorded Min Loss 0.0024746486451476812\n",
      "Iteration: 13/350  Current Loss: 0.00303770718164742 and previously recorded Min Loss 0.0024746486451476812\n",
      "Iteration: 14/360  Current Loss: 0.0023411717265844345 and previously recorded Min Loss 0.0024746486451476812\n",
      " Model saved\n",
      "Iteration: 14/370  Current Loss: 0.002284185728058219 and previously recorded Min Loss 0.0023411717265844345\n",
      " Model saved\n",
      "Iteration: 15/380  Current Loss: 0.002652039984241128 and previously recorded Min Loss 0.002284185728058219\n",
      "Iteration: 15/390  Current Loss: 0.0021633661817759275 and previously recorded Min Loss 0.002284185728058219\n",
      " Model saved\n",
      "Iteration: 15/400  Current Loss: 0.0020948024466633797 and previously recorded Min Loss 0.0021633661817759275\n",
      " Model saved\n",
      "Iteration: 16/410  Current Loss: 0.0023453827016055584 and previously recorded Min Loss 0.0020948024466633797\n",
      "Iteration: 16/420  Current Loss: 0.0019633350893855095 and previously recorded Min Loss 0.0020948024466633797\n",
      " Model saved\n",
      "Iteration: 17/430  Current Loss: 0.0019284086301922798 and previously recorded Min Loss 0.0019633350893855095\n",
      " Model saved\n",
      "Iteration: 17/440  Current Loss: 0.002265217946842313 and previously recorded Min Loss 0.0019284086301922798\n",
      "Iteration: 17/450  Current Loss: 0.0018641864880919456 and previously recorded Min Loss 0.0019284086301922798\n",
      " Model saved\n",
      "Iteration: 18/460  Current Loss: 0.0017967200838029385 and previously recorded Min Loss 0.0018641864880919456\n",
      " Model saved\n",
      "Iteration: 18/470  Current Loss: 0.0018723895773291588 and previously recorded Min Loss 0.0017967200838029385\n",
      "Iteration: 19/480  Current Loss: 0.0017643301980569959 and previously recorded Min Loss 0.0017967200838029385\n",
      " Model saved\n",
      "Iteration: 19/490  Current Loss: 0.0019148460123687983 and previously recorded Min Loss 0.0017643301980569959\n",
      "Iteration: 19/500  Current Loss: 0.001962199341505766 and previously recorded Min Loss 0.0017643301980569959\n",
      "Iteration: 20/510  Current Loss: 0.0018421040149405599 and previously recorded Min Loss 0.0017643301980569959\n",
      "Iteration: 20/520  Current Loss: 0.0017438180511817336 and previously recorded Min Loss 0.0017643301980569959\n",
      " Model saved\n",
      "Iteration: 21/530  Current Loss: 0.0016791359521448612 and previously recorded Min Loss 0.0017438180511817336\n",
      " Model saved\n",
      "Iteration: 21/540  Current Loss: 0.001962970709428191 and previously recorded Min Loss 0.0016791359521448612\n",
      "Iteration: 21/550  Current Loss: 0.0018986701034009457 and previously recorded Min Loss 0.0016791359521448612\n",
      "Iteration: 22/560  Current Loss: 0.002092695329338312 and previously recorded Min Loss 0.0016791359521448612\n",
      "Iteration: 22/570  Current Loss: 0.0016944260569289327 and previously recorded Min Loss 0.0016791359521448612\n",
      "Iteration: 23/580  Current Loss: 0.0016537343617528677 and previously recorded Min Loss 0.0016791359521448612\n",
      " Model saved\n",
      "Iteration: 23/590  Current Loss: 0.0021002988796681166 and previously recorded Min Loss 0.0016537343617528677\n",
      "Iteration: 23/600  Current Loss: 0.0016677480889484286 and previously recorded Min Loss 0.0016537343617528677\n",
      "Iteration: 24/610  Current Loss: 0.001509993802756071 and previously recorded Min Loss 0.0016537343617528677\n",
      " Model saved\n",
      "Iteration: 24/620  Current Loss: 0.0015378755051642656 and previously recorded Min Loss 0.001509993802756071\n",
      "Iteration: 25/630  Current Loss: 0.0015121429460123181 and previously recorded Min Loss 0.001509993802756071\n",
      "Iteration: 25/640  Current Loss: 0.0015799145912751555 and previously recorded Min Loss 0.001509993802756071\n",
      "Iteration: 25/650  Current Loss: 0.001566983526572585 and previously recorded Min Loss 0.001509993802756071\n",
      "Iteration: 26/660  Current Loss: 0.0017005890840664506 and previously recorded Min Loss 0.001509993802756071\n",
      "Iteration: 26/670  Current Loss: 0.0015311641618609428 and previously recorded Min Loss 0.001509993802756071\n",
      "Iteration: 27/680  Current Loss: 0.0014097552048042417 and previously recorded Min Loss 0.001509993802756071\n",
      " Model saved\n",
      "Iteration: 27/690  Current Loss: 0.0013985903933644295 and previously recorded Min Loss 0.0014097552048042417\n",
      " Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 27/700  Current Loss: 0.001559165888465941 and previously recorded Min Loss 0.0013985903933644295\n",
      "Iteration: 28/710  Current Loss: 0.0014829060528427362 and previously recorded Min Loss 0.0013985903933644295\n",
      "Iteration: 28/720  Current Loss: 0.0016417732695117593 and previously recorded Min Loss 0.0013985903933644295\n",
      "Iteration: 29/730  Current Loss: 0.0013524085516110063 and previously recorded Min Loss 0.0013985903933644295\n",
      " Model saved\n",
      "Iteration: 29/740  Current Loss: 0.0013529793359339237 and previously recorded Min Loss 0.0013524085516110063\n",
      "Iteration: 29/750  Current Loss: 0.0014576305402442813 and previously recorded Min Loss 0.0013524085516110063\n",
      "Iteration: 30/760  Current Loss: 0.0013736658729612827 and previously recorded Min Loss 0.0013524085516110063\n",
      "Iteration: 30/770  Current Loss: 0.0012986588990315795 and previously recorded Min Loss 0.0013524085516110063\n",
      " Model saved\n",
      "Iteration: 31/780  Current Loss: 0.0013784660259261727 and previously recorded Min Loss 0.0012986588990315795\n",
      "Iteration: 31/790  Current Loss: 0.0013878956669941545 and previously recorded Min Loss 0.0012986588990315795\n",
      "Iteration: 31/800  Current Loss: 0.0012800786644220352 and previously recorded Min Loss 0.0012986588990315795\n",
      " Model saved\n",
      "Iteration: 32/810  Current Loss: 0.0014520924305543303 and previously recorded Min Loss 0.0012800786644220352\n",
      "Iteration: 32/820  Current Loss: 0.0013149696169421077 and previously recorded Min Loss 0.0012800786644220352\n",
      "Iteration: 33/830  Current Loss: 0.0013889229157939553 and previously recorded Min Loss 0.0012800786644220352\n",
      "Iteration: 33/840  Current Loss: 0.0012354791397228837 and previously recorded Min Loss 0.0012800786644220352\n",
      " Model saved\n",
      "Iteration: 33/850  Current Loss: 0.001183797256089747 and previously recorded Min Loss 0.0012354791397228837\n",
      " Model saved\n",
      "Iteration: 34/860  Current Loss: 0.0013561936793848872 and previously recorded Min Loss 0.001183797256089747\n",
      "Iteration: 34/870  Current Loss: 0.001277024275623262 and previously recorded Min Loss 0.001183797256089747\n",
      "Iteration: 35/880  Current Loss: 0.0012985824141651392 and previously recorded Min Loss 0.001183797256089747\n",
      "Iteration: 35/890  Current Loss: 0.001187688554637134 and previously recorded Min Loss 0.001183797256089747\n",
      "Iteration: 35/900  Current Loss: 0.0015990507090464234 and previously recorded Min Loss 0.001183797256089747\n",
      "Iteration: 36/910  Current Loss: 0.0011791946599259973 and previously recorded Min Loss 0.001183797256089747\n",
      " Model saved\n",
      "Iteration: 36/920  Current Loss: 0.002033754950389266 and previously recorded Min Loss 0.0011791946599259973\n",
      "Iteration: 37/930  Current Loss: 0.001427680253982544 and previously recorded Min Loss 0.0011791946599259973\n",
      "Iteration: 37/940  Current Loss: 0.0012895234394818544 and previously recorded Min Loss 0.0011791946599259973\n",
      "Iteration: 37/950  Current Loss: 0.001119024702347815 and previously recorded Min Loss 0.0011791946599259973\n",
      " Model saved\n",
      "Iteration: 38/960  Current Loss: 0.001215816126205027 and previously recorded Min Loss 0.001119024702347815\n",
      "Iteration: 38/970  Current Loss: 0.0010872607817873359 and previously recorded Min Loss 0.001119024702347815\n",
      " Model saved\n",
      "Iteration: 39/980  Current Loss: 0.00105810328386724 and previously recorded Min Loss 0.0010872607817873359\n",
      " Model saved\n",
      "Iteration: 39/990  Current Loss: 0.0011503836140036583 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 39/1000  Current Loss: 0.001110945246182382 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 40/1010  Current Loss: 0.001249426626600325 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 40/1020  Current Loss: 0.0014267857186496258 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 41/1030  Current Loss: 0.0012709434377029538 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 41/1040  Current Loss: 0.0011232331162318587 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 41/1050  Current Loss: 0.001134560676291585 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 42/1060  Current Loss: 0.0015253206947818398 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 42/1070  Current Loss: 0.0013455781154334545 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 43/1080  Current Loss: 0.0011219639563933015 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 43/1090  Current Loss: 0.0012451178627088666 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 43/1100  Current Loss: 0.0012226735707372427 and previously recorded Min Loss 0.00105810328386724\n",
      "Iteration: 44/1110  Current Loss: 0.0009894188260659575 and previously recorded Min Loss 0.00105810328386724\n",
      " Model saved\n",
      "Iteration: 44/1120  Current Loss: 0.001154789817519486 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 45/1130  Current Loss: 0.0010337803978472948 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 45/1140  Current Loss: 0.0010790801607072353 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 45/1150  Current Loss: 0.0011474312050268054 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 46/1160  Current Loss: 0.001205497421324253 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 46/1170  Current Loss: 0.001006769947707653 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 47/1180  Current Loss: 0.0011636436684057117 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 47/1190  Current Loss: 0.0013192488113418221 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 47/1200  Current Loss: 0.0011339670745655894 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 48/1210  Current Loss: 0.0010224158177152276 and previously recorded Min Loss 0.0009894188260659575\n",
      "Iteration: 48/1220  Current Loss: 0.0009745049756020308 and previously recorded Min Loss 0.0009894188260659575\n",
      " Model saved\n",
      "Iteration: 49/1230  Current Loss: 0.0010018674656748772 and previously recorded Min Loss 0.0009745049756020308\n",
      "Iteration: 49/1240  Current Loss: 0.0009640388889238238 and previously recorded Min Loss 0.0009745049756020308\n",
      " Model saved\n",
      "Iteration: 49/1250  Current Loss: 0.0009679318754933774 and previously recorded Min Loss 0.0009640388889238238\n",
      "Iteration: 50/1260  Current Loss: 0.0009515599813312292 and previously recorded Min Loss 0.0009640388889238238\n",
      " Model saved\n",
      "Iteration: 50/1270  Current Loss: 0.000972539943177253 and previously recorded Min Loss 0.0009515599813312292\n",
      "Iteration: 51/1280  Current Loss: 0.0009367851307615638 and previously recorded Min Loss 0.0009515599813312292\n",
      " Model saved\n",
      "Iteration: 51/1290  Current Loss: 0.0009628693806007504 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 51/1300  Current Loss: 0.0011239590821787715 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 52/1310  Current Loss: 0.00113149534445256 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 52/1320  Current Loss: 0.0010545285185799003 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 53/1330  Current Loss: 0.0009471257217228413 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 53/1340  Current Loss: 0.0010070083662867546 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 53/1350  Current Loss: 0.0009660894284024835 and previously recorded Min Loss 0.0009367851307615638\n",
      "Iteration: 54/1360  Current Loss: 0.0008831738959997892 and previously recorded Min Loss 0.0009367851307615638\n",
      " Model saved\n",
      "Iteration: 54/1370  Current Loss: 0.0011578577104955912 and previously recorded Min Loss 0.0008831738959997892\n",
      "Iteration: 55/1380  Current Loss: 0.0009530780371278524 and previously recorded Min Loss 0.0008831738959997892\n",
      "Iteration: 55/1390  Current Loss: 0.0010559303918853402 and previously recorded Min Loss 0.0008831738959997892\n",
      "Iteration: 55/1400  Current Loss: 0.0008822675445117056 and previously recorded Min Loss 0.0008831738959997892\n",
      " Model saved\n",
      "Iteration: 56/1410  Current Loss: 0.0010112334275618196 and previously recorded Min Loss 0.0008822675445117056\n",
      "Iteration: 56/1420  Current Loss: 0.0008763322839513421 and previously recorded Min Loss 0.0008822675445117056\n",
      " Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57/1430  Current Loss: 0.0012688350398093462 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 57/1440  Current Loss: 0.0009674304164946079 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 57/1450  Current Loss: 0.0012833145447075367 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 58/1460  Current Loss: 0.0009750357130542397 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 58/1470  Current Loss: 0.0009527300135232508 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 59/1480  Current Loss: 0.0009788667084649205 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 59/1490  Current Loss: 0.0009404552984051406 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 59/1500  Current Loss: 0.0009841776918619871 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 60/1510  Current Loss: 0.0008824813412502408 and previously recorded Min Loss 0.0008763322839513421\n",
      "Iteration: 60/1520  Current Loss: 0.000850964745040983 and previously recorded Min Loss 0.0008763322839513421\n",
      " Model saved\n",
      "Iteration: 61/1530  Current Loss: 0.0011633036192506552 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 61/1540  Current Loss: 0.0008804327226243913 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 61/1550  Current Loss: 0.0012229102430865169 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 62/1560  Current Loss: 0.0016895883018150926 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 62/1570  Current Loss: 0.0015340172685682774 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 63/1580  Current Loss: 0.0012658642372116446 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 63/1590  Current Loss: 0.0009384035947732627 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 63/1600  Current Loss: 0.000904918066225946 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 64/1610  Current Loss: 0.000984760234132409 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 64/1620  Current Loss: 0.0009474476682953537 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 65/1630  Current Loss: 0.0008941260748542845 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 65/1640  Current Loss: 0.0012236767215654254 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 65/1650  Current Loss: 0.0009760339744389057 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 66/1660  Current Loss: 0.0010426428634673357 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 66/1670  Current Loss: 0.0008583508897572756 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 67/1680  Current Loss: 0.0008910045144148171 and previously recorded Min Loss 0.000850964745040983\n",
      "Iteration: 67/1690  Current Loss: 0.0008013966144062579 and previously recorded Min Loss 0.000850964745040983\n",
      " Model saved\n",
      "Iteration: 67/1700  Current Loss: 0.000961865356657654 and previously recorded Min Loss 0.0008013966144062579\n",
      "Iteration: 68/1710  Current Loss: 0.0007729243952780962 and previously recorded Min Loss 0.0008013966144062579\n",
      " Model saved\n",
      "Iteration: 68/1720  Current Loss: 0.0007785078487358987 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 69/1730  Current Loss: 0.0008315175655297935 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 69/1740  Current Loss: 0.0008646200876682997 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 69/1750  Current Loss: 0.0009034594986587763 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 70/1760  Current Loss: 0.0009999495232477784 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 70/1770  Current Loss: 0.0010247856844216585 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 71/1780  Current Loss: 0.0008381649968214333 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 71/1790  Current Loss: 0.0009486903436481953 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 71/1800  Current Loss: 0.0008771614520810544 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 72/1810  Current Loss: 0.0009024990140460432 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 72/1820  Current Loss: 0.0009935839334502816 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 73/1830  Current Loss: 0.0010910396231338382 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 73/1840  Current Loss: 0.0008802640368230641 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 73/1850  Current Loss: 0.0008274293504655361 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 74/1860  Current Loss: 0.0008243442862294614 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 74/1870  Current Loss: 0.0012978017330169678 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 75/1880  Current Loss: 0.000964995997492224 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 75/1890  Current Loss: 0.0008446917054243386 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 75/1900  Current Loss: 0.0009638081537559628 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 76/1910  Current Loss: 0.0008090919582173228 and previously recorded Min Loss 0.0007729243952780962\n",
      "Iteration: 76/1920  Current Loss: 0.0007675288943573833 and previously recorded Min Loss 0.0007729243952780962\n",
      " Model saved\n",
      "Iteration: 77/1930  Current Loss: 0.0010667791357263923 and previously recorded Min Loss 0.0007675288943573833\n",
      "Iteration: 77/1940  Current Loss: 0.0010364496847614646 and previously recorded Min Loss 0.0007675288943573833\n",
      "Iteration: 77/1950  Current Loss: 0.0007785026100464165 and previously recorded Min Loss 0.0007675288943573833\n",
      "Iteration: 78/1960  Current Loss: 0.0007131585734896362 and previously recorded Min Loss 0.0007675288943573833\n",
      " Model saved\n",
      "Iteration: 78/1970  Current Loss: 0.0007312798406928778 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 79/1980  Current Loss: 0.0007996652857400477 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 79/1990  Current Loss: 0.0009756283252499998 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 79/2000  Current Loss: 0.0010274846572428942 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 80/2010  Current Loss: 0.0008579869172535837 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 80/2020  Current Loss: 0.0009290544549003243 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 81/2030  Current Loss: 0.0010028945980593562 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 81/2040  Current Loss: 0.0008951755589805543 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 81/2050  Current Loss: 0.000865260255523026 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 82/2060  Current Loss: 0.0008133298833854496 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 82/2070  Current Loss: 0.0010428738314658403 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 83/2080  Current Loss: 0.0007706883479841053 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 83/2090  Current Loss: 0.0007754031685180962 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 83/2100  Current Loss: 0.0008575485553592443 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 84/2110  Current Loss: 0.0007886845269240439 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 84/2120  Current Loss: 0.000800571870058775 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 85/2130  Current Loss: 0.0007504909299314022 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 85/2140  Current Loss: 0.0008584200986661017 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 85/2150  Current Loss: 0.0007935010362416506 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 86/2160  Current Loss: 0.0008591425139456987 and previously recorded Min Loss 0.0007131585734896362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 86/2170  Current Loss: 0.0007277860422618687 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 87/2180  Current Loss: 0.0008651278330944479 and previously recorded Min Loss 0.0007131585734896362\n",
      "Iteration: 87/2190  Current Loss: 0.0006855147075839341 and previously recorded Min Loss 0.0007131585734896362\n",
      " Model saved\n",
      "Iteration: 87/2200  Current Loss: 0.001376667874865234 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 88/2210  Current Loss: 0.0010425405343994498 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 88/2220  Current Loss: 0.0020227462518960238 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 89/2230  Current Loss: 0.0009309986489824951 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 89/2240  Current Loss: 0.0008475682116113603 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 89/2250  Current Loss: 0.000711538945324719 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 90/2260  Current Loss: 0.0012265765108168125 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 90/2270  Current Loss: 0.0014347709948197007 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 91/2280  Current Loss: 0.0008157555130310357 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 91/2290  Current Loss: 0.0009696883498691022 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 91/2300  Current Loss: 0.000834622944239527 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 92/2310  Current Loss: 0.0009135283180512488 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 92/2320  Current Loss: 0.0010348506039008498 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 93/2330  Current Loss: 0.0007486615795642138 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 93/2340  Current Loss: 0.0008388425339944661 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 93/2350  Current Loss: 0.0007773902616463602 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 94/2360  Current Loss: 0.0008578083943575621 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 94/2370  Current Loss: 0.000918763515073806 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 95/2380  Current Loss: 0.0009168428368866444 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 95/2390  Current Loss: 0.0007635889924131334 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 95/2400  Current Loss: 0.0007204168941825628 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 96/2410  Current Loss: 0.0007162471301853657 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 96/2420  Current Loss: 0.0007909780251793563 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 97/2430  Current Loss: 0.0007378659211099148 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 97/2440  Current Loss: 0.0007252924842759967 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 97/2450  Current Loss: 0.0008464398561045527 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 98/2460  Current Loss: 0.0010151690803468227 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 98/2470  Current Loss: 0.0007386169745586812 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 99/2480  Current Loss: 0.0012053281534463167 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 99/2490  Current Loss: 0.0008267309749498963 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 99/2500  Current Loss: 0.0009370965417474508 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 100/2510  Current Loss: 0.001232653041370213 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 100/2520  Current Loss: 0.0007422516355291009 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 101/2530  Current Loss: 0.0007875376613810658 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 101/2540  Current Loss: 0.0007265547174029052 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 101/2550  Current Loss: 0.0008211199310608208 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 102/2560  Current Loss: 0.0009728714940138161 and previously recorded Min Loss 0.0006855147075839341\n",
      "Iteration: 102/2570  Current Loss: 0.0006812984356656671 and previously recorded Min Loss 0.0006855147075839341\n",
      " Model saved\n",
      "Iteration: 103/2580  Current Loss: 0.0008073559729382396 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 103/2590  Current Loss: 0.0009316820069216192 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 103/2600  Current Loss: 0.0008698406163603067 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 104/2610  Current Loss: 0.0007860378827899694 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 104/2620  Current Loss: 0.0011432220926508307 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 105/2630  Current Loss: 0.0008315311861224473 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 105/2640  Current Loss: 0.0007023175712674856 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 105/2650  Current Loss: 0.0007492906879633665 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 106/2660  Current Loss: 0.0007122247479856014 and previously recorded Min Loss 0.0006812984356656671\n",
      "Iteration: 106/2670  Current Loss: 0.0006811972125433385 and previously recorded Min Loss 0.0006812984356656671\n",
      " Model saved\n",
      "Iteration: 107/2680  Current Loss: 0.0007015134324319661 and previously recorded Min Loss 0.0006811972125433385\n",
      "Iteration: 107/2690  Current Loss: 0.0006797524401918054 and previously recorded Min Loss 0.0006811972125433385\n",
      " Model saved\n",
      "Iteration: 107/2700  Current Loss: 0.0007281603175215423 and previously recorded Min Loss 0.0006797524401918054\n",
      "Iteration: 108/2710  Current Loss: 0.0006599387852475047 and previously recorded Min Loss 0.0006797524401918054\n",
      " Model saved\n",
      "Iteration: 108/2720  Current Loss: 0.000770071055740118 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 109/2730  Current Loss: 0.0007425830117426813 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 109/2740  Current Loss: 0.0007449490949511528 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 109/2750  Current Loss: 0.0007073906599543989 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 110/2760  Current Loss: 0.0006702918908558786 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 110/2770  Current Loss: 0.0006990882684476674 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 111/2780  Current Loss: 0.0009119388996623456 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 111/2790  Current Loss: 0.0006858832784928381 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 111/2800  Current Loss: 0.0007497061160393059 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 112/2810  Current Loss: 0.0006999372271820903 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 112/2820  Current Loss: 0.0008533468935638666 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 113/2830  Current Loss: 0.0007561305537819862 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 113/2840  Current Loss: 0.0006947321235202253 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 113/2850  Current Loss: 0.0006953025585971773 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 114/2860  Current Loss: 0.0008024221169762313 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 114/2870  Current Loss: 0.0009442948503419757 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 115/2880  Current Loss: 0.0009034689865075052 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 115/2890  Current Loss: 0.0007487447001039982 and previously recorded Min Loss 0.0006599387852475047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 115/2900  Current Loss: 0.0006856693653389812 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 116/2910  Current Loss: 0.0006664925604127347 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 116/2920  Current Loss: 0.0012656195322051644 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 117/2930  Current Loss: 0.0013034733710810542 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 117/2940  Current Loss: 0.001361499773338437 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 117/2950  Current Loss: 0.0008860623929649591 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 118/2960  Current Loss: 0.0008002608083188534 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 118/2970  Current Loss: 0.0007063727825880051 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 119/2980  Current Loss: 0.0006932916003279388 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 119/2990  Current Loss: 0.0006700410740450025 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 119/3000  Current Loss: 0.000667709216941148 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 120/3010  Current Loss: 0.0006858616252429783 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 120/3020  Current Loss: 0.0007326222257688642 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 121/3030  Current Loss: 0.0011418163776397705 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 121/3040  Current Loss: 0.0007682469440624118 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 121/3050  Current Loss: 0.0008375514880754054 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 122/3060  Current Loss: 0.0007947947015054524 and previously recorded Min Loss 0.0006599387852475047\n",
      "Iteration: 122/3070  Current Loss: 0.0006515613640658557 and previously recorded Min Loss 0.0006599387852475047\n",
      " Model saved\n",
      "Iteration: 123/3080  Current Loss: 0.0008068440365605056 and previously recorded Min Loss 0.0006515613640658557\n",
      "Iteration: 123/3090  Current Loss: 0.000682592683006078 and previously recorded Min Loss 0.0006515613640658557\n",
      "Iteration: 123/3100  Current Loss: 0.0006428424385376275 and previously recorded Min Loss 0.0006515613640658557\n",
      " Model saved\n",
      "Iteration: 124/3110  Current Loss: 0.0007316122064366937 and previously recorded Min Loss 0.0006428424385376275\n",
      "Iteration: 124/3120  Current Loss: 0.0006983128841966391 and previously recorded Min Loss 0.0006428424385376275\n",
      "Iteration: 125/3130  Current Loss: 0.0006279313820414245 and previously recorded Min Loss 0.0006428424385376275\n",
      " Model saved\n",
      "Iteration: 125/3140  Current Loss: 0.0006217691698111594 and previously recorded Min Loss 0.0006279313820414245\n",
      " Model saved\n",
      "Iteration: 125/3150  Current Loss: 0.0006147944368422031 and previously recorded Min Loss 0.0006217691698111594\n",
      " Model saved\n",
      "Iteration: 126/3160  Current Loss: 0.0006769820465706289 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 126/3170  Current Loss: 0.0007202844717539847 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 127/3180  Current Loss: 0.0008380341459996998 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 127/3190  Current Loss: 0.0007017759489826858 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 127/3200  Current Loss: 0.0006864874740131199 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 128/3210  Current Loss: 0.0006211845320649445 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 128/3220  Current Loss: 0.0013634002534672618 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 129/3230  Current Loss: 0.0008478524396196008 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 129/3240  Current Loss: 0.0010051981080323458 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 129/3250  Current Loss: 0.000674715731292963 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 130/3260  Current Loss: 0.0007213939097709954 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 130/3270  Current Loss: 0.0006501819589175284 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 131/3280  Current Loss: 0.0008661628817208111 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 131/3290  Current Loss: 0.0007852397975511849 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 131/3300  Current Loss: 0.0007335573900490999 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 132/3310  Current Loss: 0.0007993539911694825 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 132/3320  Current Loss: 0.000727423932403326 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 133/3330  Current Loss: 0.0006780584808439016 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 133/3340  Current Loss: 0.0009105614735744894 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 133/3350  Current Loss: 0.0007347823120653629 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 134/3360  Current Loss: 0.001116067753173411 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 134/3370  Current Loss: 0.0009635601891204715 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 135/3380  Current Loss: 0.0007061575306579471 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 135/3390  Current Loss: 0.000688074913341552 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 135/3400  Current Loss: 0.0007006626110523939 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 136/3410  Current Loss: 0.0006820005364716053 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 136/3420  Current Loss: 0.0007429199176840484 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 137/3430  Current Loss: 0.0007011874695308506 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 137/3440  Current Loss: 0.0006360684055835009 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 137/3450  Current Loss: 0.0007129809237085283 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 138/3460  Current Loss: 0.0007535101030953228 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 138/3470  Current Loss: 0.0006711497553624213 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 139/3480  Current Loss: 0.0007225996232591569 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 139/3490  Current Loss: 0.0008219798910431564 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 139/3500  Current Loss: 0.0006923916516825557 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 140/3510  Current Loss: 0.0006797477253712714 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 140/3520  Current Loss: 0.0010509490966796875 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 141/3530  Current Loss: 0.0006910990341566503 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 141/3540  Current Loss: 0.0006347503513097763 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 141/3550  Current Loss: 0.00070270209107548 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 142/3560  Current Loss: 0.0006478585419245064 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 142/3570  Current Loss: 0.0007786253117956221 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 143/3580  Current Loss: 0.0007919075433164835 and previously recorded Min Loss 0.0006147944368422031\n",
      "Iteration: 143/3590  Current Loss: 0.0006101836333982646 and previously recorded Min Loss 0.0006147944368422031\n",
      " Model saved\n",
      "Iteration: 143/3600  Current Loss: 0.0006493694381788373 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 144/3610  Current Loss: 0.0006188765983097255 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 144/3620  Current Loss: 0.0007289695786312222 and previously recorded Min Loss 0.0006101836333982646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 145/3630  Current Loss: 0.0007002821075730026 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 145/3640  Current Loss: 0.000615687866229564 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 145/3650  Current Loss: 0.0007171874749474227 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 146/3660  Current Loss: 0.0007330169319175184 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 146/3670  Current Loss: 0.0007518380880355835 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 147/3680  Current Loss: 0.0007967788842506707 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 147/3690  Current Loss: 0.0007609085296280682 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 147/3700  Current Loss: 0.0006858590641058981 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 148/3710  Current Loss: 0.0007774765836074948 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 148/3720  Current Loss: 0.0009392512729391456 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 149/3730  Current Loss: 0.0007552325259894133 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 149/3740  Current Loss: 0.000759958871640265 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 149/3750  Current Loss: 0.0007080624927766621 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 150/3760  Current Loss: 0.0006813994841650128 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 150/3770  Current Loss: 0.0008556294487789273 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 151/3780  Current Loss: 0.0006208561244420707 and previously recorded Min Loss 0.0006101836333982646\n",
      "Iteration: 151/3790  Current Loss: 0.000609817449003458 and previously recorded Min Loss 0.0006101836333982646\n",
      " Model saved\n",
      "Iteration: 151/3800  Current Loss: 0.000816917628981173 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 152/3810  Current Loss: 0.0008498268434777856 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 152/3820  Current Loss: 0.000832855817861855 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 153/3830  Current Loss: 0.0007844293140806258 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 153/3840  Current Loss: 0.0007272501825354993 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 153/3850  Current Loss: 0.0006238200585357845 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 154/3860  Current Loss: 0.0006444831960834563 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 154/3870  Current Loss: 0.000795136031229049 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 155/3880  Current Loss: 0.0006822616560384631 and previously recorded Min Loss 0.000609817449003458\n",
      "Iteration: 155/3890  Current Loss: 0.0005878759548068047 and previously recorded Min Loss 0.000609817449003458\n",
      " Model saved\n",
      "Iteration: 155/3900  Current Loss: 0.0006045472691766918 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 156/3910  Current Loss: 0.0006141769117675722 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 156/3920  Current Loss: 0.0006255068001337349 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 157/3930  Current Loss: 0.0007633475470356643 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 157/3940  Current Loss: 0.0005969150806777179 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 157/3950  Current Loss: 0.0006373936193995178 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 158/3960  Current Loss: 0.0007364570628851652 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 158/3970  Current Loss: 0.0007362584583461285 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 159/3980  Current Loss: 0.0007026960956864059 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 159/3990  Current Loss: 0.0007240954437293112 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 159/4000  Current Loss: 0.0006816709646955132 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 160/4010  Current Loss: 0.0006137109594419599 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 160/4020  Current Loss: 0.002105393446981907 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 161/4030  Current Loss: 0.0010308925993740559 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 161/4040  Current Loss: 0.0006624492234550416 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 161/4050  Current Loss: 0.0009219059138558805 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 162/4060  Current Loss: 0.0008860570378601551 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 162/4070  Current Loss: 0.0007435231236740947 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 163/4080  Current Loss: 0.0006905575282871723 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 163/4090  Current Loss: 0.0007947291014716029 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 163/4100  Current Loss: 0.0006684529362246394 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 164/4110  Current Loss: 0.0007493934826925397 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 164/4120  Current Loss: 0.0006983464118093252 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 165/4130  Current Loss: 0.0006311570177786052 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 165/4140  Current Loss: 0.0005981690483167768 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 165/4150  Current Loss: 0.0006082668551243842 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 166/4160  Current Loss: 0.0008354586898349226 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 166/4170  Current Loss: 0.0006211479776538908 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 167/4180  Current Loss: 0.000698908232152462 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 167/4190  Current Loss: 0.0006048068753443658 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 167/4200  Current Loss: 0.000646863307338208 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 168/4210  Current Loss: 0.0006230559665709734 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 168/4220  Current Loss: 0.0006955585558898747 and previously recorded Min Loss 0.0005878759548068047\n",
      "Iteration: 169/4230  Current Loss: 0.0005871932953596115 and previously recorded Min Loss 0.0005878759548068047\n",
      " Model saved\n",
      "Iteration: 169/4240  Current Loss: 0.0006382653373293579 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 169/4250  Current Loss: 0.0006858689012005925 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 170/4260  Current Loss: 0.0006269282894209027 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 170/4270  Current Loss: 0.0007756541017442942 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 171/4280  Current Loss: 0.0006066152709536254 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 171/4290  Current Loss: 0.0008178301504813135 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 171/4300  Current Loss: 0.0006275905179791152 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 172/4310  Current Loss: 0.0007145098643377423 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 172/4320  Current Loss: 0.0007184197311289608 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 173/4330  Current Loss: 0.0006352763739414513 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 173/4340  Current Loss: 0.0008498076931573451 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 173/4350  Current Loss: 0.0006510612438432872 and previously recorded Min Loss 0.0005871932953596115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 174/4360  Current Loss: 0.0007543369429185987 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 174/4370  Current Loss: 0.000654502771794796 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 175/4380  Current Loss: 0.0007189985481090844 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 175/4390  Current Loss: 0.0010660721454769373 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 175/4400  Current Loss: 0.0008964620647020638 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 176/4410  Current Loss: 0.0007147914147935808 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 176/4420  Current Loss: 0.0013140704249963164 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 177/4430  Current Loss: 0.0010637615341693163 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 177/4440  Current Loss: 0.0008200774318538606 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 177/4450  Current Loss: 0.0008286010124720633 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 178/4460  Current Loss: 0.0009378261747770011 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 178/4470  Current Loss: 0.0008403395768254995 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 179/4480  Current Loss: 0.000854285666719079 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 179/4490  Current Loss: 0.000712888257112354 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 179/4500  Current Loss: 0.0006543313502334058 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 180/4510  Current Loss: 0.0006805405137129128 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 180/4520  Current Loss: 0.0006589078693650663 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 181/4530  Current Loss: 0.0006532442639581859 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 181/4540  Current Loss: 0.0007038502371869981 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 181/4550  Current Loss: 0.0006963632185943425 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 182/4560  Current Loss: 0.0007686063763685524 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 182/4570  Current Loss: 0.0006609898409806192 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 183/4580  Current Loss: 0.0006225236575119197 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 183/4590  Current Loss: 0.0006827900069765747 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 183/4600  Current Loss: 0.0006426000036299229 and previously recorded Min Loss 0.0005871932953596115\n",
      "Iteration: 184/4610  Current Loss: 0.0005862482357770205 and previously recorded Min Loss 0.0005871932953596115\n",
      " Model saved\n",
      "Iteration: 184/4620  Current Loss: 0.0007763279136270285 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 185/4630  Current Loss: 0.0006461797165684402 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 185/4640  Current Loss: 0.0018617737805470824 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 185/4650  Current Loss: 0.0006469711661338806 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 186/4660  Current Loss: 0.0009731485042721033 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 186/4670  Current Loss: 0.0006229912978596985 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 187/4680  Current Loss: 0.0006727702566422522 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 187/4690  Current Loss: 0.0007023008656688035 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 187/4700  Current Loss: 0.0006368236499838531 and previously recorded Min Loss 0.0005862482357770205\n",
      "Iteration: 188/4710  Current Loss: 0.0005764426896348596 and previously recorded Min Loss 0.0005862482357770205\n",
      " Model saved\n",
      "Iteration: 188/4720  Current Loss: 0.0006226797122508287 and previously recorded Min Loss 0.0005764426896348596\n",
      "Iteration: 189/4730  Current Loss: 0.0005672424449585378 and previously recorded Min Loss 0.0005764426896348596\n",
      " Model saved\n",
      "Iteration: 189/4740  Current Loss: 0.0005884864367544651 and previously recorded Min Loss 0.0005672424449585378\n",
      "Iteration: 189/4750  Current Loss: 0.0005632532411254942 and previously recorded Min Loss 0.0005672424449585378\n",
      " Model saved\n",
      "Iteration: 190/4760  Current Loss: 0.0005814610049128532 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 190/4770  Current Loss: 0.000588010938372463 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 191/4780  Current Loss: 0.0005771584110334516 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 191/4790  Current Loss: 0.0006138480384834111 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 191/4800  Current Loss: 0.0006012339144945145 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 192/4810  Current Loss: 0.0005740756168961525 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 192/4820  Current Loss: 0.0005740381893701851 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 193/4830  Current Loss: 0.0008969094487838447 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 193/4840  Current Loss: 0.0011151236249133945 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 193/4850  Current Loss: 0.000684888509567827 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 194/4860  Current Loss: 0.0006673384923487902 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 194/4870  Current Loss: 0.0007002725033089519 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 195/4880  Current Loss: 0.0006802605930715799 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 195/4890  Current Loss: 0.0006577550666406751 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 195/4900  Current Loss: 0.0006281843525357544 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 196/4910  Current Loss: 0.0007504344685003161 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 196/4920  Current Loss: 0.000665809609927237 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 197/4930  Current Loss: 0.0006304156850092113 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 197/4940  Current Loss: 0.0006533152773045003 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 197/4950  Current Loss: 0.0006255492917262018 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 198/4960  Current Loss: 0.000600283732637763 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 198/4970  Current Loss: 0.000619620259385556 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 199/4980  Current Loss: 0.0005980670102871954 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 199/4990  Current Loss: 0.0006122604245319963 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 199/5000  Current Loss: 0.000615180004388094 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 200/5010  Current Loss: 0.0006084836204536259 and previously recorded Min Loss 0.0005632532411254942\n",
      "Iteration: 200/5020  Current Loss: 0.0005626562051475048 and previously recorded Min Loss 0.0005632532411254942\n",
      " Model saved\n",
      "Iteration: 201/5030  Current Loss: 0.0006617333856411278 and previously recorded Min Loss 0.0005626562051475048\n",
      "Iteration: 201/5040  Current Loss: 0.0006335836369544268 and previously recorded Min Loss 0.0005626562051475048\n",
      "Iteration: 201/5050  Current Loss: 0.0005853752372786403 and previously recorded Min Loss 0.0005626562051475048\n",
      "Iteration: 202/5060  Current Loss: 0.0005921372212469578 and previously recorded Min Loss 0.0005626562051475048\n",
      "Iteration: 202/5070  Current Loss: 0.0005606950144283473 and previously recorded Min Loss 0.0005626562051475048\n",
      " Model saved\n",
      "Iteration: 203/5080  Current Loss: 0.0005573492380790412 and previously recorded Min Loss 0.0005606950144283473\n",
      " Model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 203/5090  Current Loss: 0.0006486769416369498 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 203/5100  Current Loss: 0.0005800571525469422 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 204/5110  Current Loss: 0.0005599215510301292 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 204/5120  Current Loss: 0.0008154288516379893 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 205/5130  Current Loss: 0.0005883423145860434 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 205/5140  Current Loss: 0.0006264812545850873 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 205/5150  Current Loss: 0.0006716061616316438 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 206/5160  Current Loss: 0.0005610277294181287 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 206/5170  Current Loss: 0.0006266468553803861 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 207/5180  Current Loss: 0.0006688370485790074 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 207/5190  Current Loss: 0.0005960562266409397 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 207/5200  Current Loss: 0.0006094801356084645 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 208/5210  Current Loss: 0.0006156322779133916 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 208/5220  Current Loss: 0.0007273241062648594 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 209/5230  Current Loss: 0.0005761375650763512 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 209/5240  Current Loss: 0.0005710465484298766 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 209/5250  Current Loss: 0.0006320981774479151 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 210/5260  Current Loss: 0.0006310206954367459 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 210/5270  Current Loss: 0.000720975105650723 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 211/5280  Current Loss: 0.0006565934745594859 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 211/5290  Current Loss: 0.0006326637230813503 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 211/5300  Current Loss: 0.0008294822764582932 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 212/5310  Current Loss: 0.0007075081812217832 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 212/5320  Current Loss: 0.0005604250472970307 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 213/5330  Current Loss: 0.0006172009743750095 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 213/5340  Current Loss: 0.0006355076911859214 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 213/5350  Current Loss: 0.0006826573517173529 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 214/5360  Current Loss: 0.000668680586386472 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 214/5370  Current Loss: 0.0006183847435750067 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 215/5380  Current Loss: 0.0005795455654151738 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 215/5390  Current Loss: 0.0006904943147674203 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 215/5400  Current Loss: 0.0007915424066595733 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 216/5410  Current Loss: 0.0006283533293753862 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 216/5420  Current Loss: 0.0007064489764161408 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 217/5430  Current Loss: 0.000683304388076067 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 217/5440  Current Loss: 0.0007362519390881062 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 217/5450  Current Loss: 0.0006718816584907472 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 218/5460  Current Loss: 0.000785531650763005 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 218/5470  Current Loss: 0.0007014794391579926 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 219/5480  Current Loss: 0.0008827706333249807 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 219/5490  Current Loss: 0.0012661278015002608 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 219/5500  Current Loss: 0.0007679825648665428 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 220/5510  Current Loss: 0.0007515400648117065 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 220/5520  Current Loss: 0.0007258202531374991 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 221/5530  Current Loss: 0.0007985522388480604 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 221/5540  Current Loss: 0.0007555630290880799 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 221/5550  Current Loss: 0.0008236857829615474 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 222/5560  Current Loss: 0.0008427502471022308 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 222/5570  Current Loss: 0.0006293521146290004 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 223/5580  Current Loss: 0.0007515980978496373 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 223/5590  Current Loss: 0.0012623355723917484 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 223/5600  Current Loss: 0.0007426343508996069 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 224/5610  Current Loss: 0.0005857288488186896 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 224/5620  Current Loss: 0.0005998450214974582 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 225/5630  Current Loss: 0.0005695106810890138 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 225/5640  Current Loss: 0.0005741198547184467 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 225/5650  Current Loss: 0.0006646537221968174 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 226/5660  Current Loss: 0.0005696472362615168 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 226/5670  Current Loss: 0.0005899557145312428 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 227/5680  Current Loss: 0.0005755280726589262 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 227/5690  Current Loss: 0.0008643103647045791 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 227/5700  Current Loss: 0.0008977261022664607 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 228/5710  Current Loss: 0.0009523652261123061 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 228/5720  Current Loss: 0.0006584911025129259 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 229/5730  Current Loss: 0.0006074506673030555 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 229/5740  Current Loss: 0.0006244324613362551 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 229/5750  Current Loss: 0.0005772075382992625 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 230/5760  Current Loss: 0.0006676623015664518 and previously recorded Min Loss 0.0005573492380790412\n",
      "Iteration: 230/5770  Current Loss: 0.0005463252309709787 and previously recorded Min Loss 0.0005573492380790412\n",
      " Model saved\n",
      "Iteration: 231/5780  Current Loss: 0.0005724563961848617 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 231/5790  Current Loss: 0.0006183703662827611 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 231/5800  Current Loss: 0.0005466029397211969 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 232/5810  Current Loss: 0.0006700955564156175 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 232/5820  Current Loss: 0.0005768869305029511 and previously recorded Min Loss 0.0005463252309709787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 233/5830  Current Loss: 0.0007232804782688618 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 233/5840  Current Loss: 0.0007097275229170918 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 233/5850  Current Loss: 0.000606356596108526 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 234/5860  Current Loss: 0.000579667801503092 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 234/5870  Current Loss: 0.0005803080275654793 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 235/5880  Current Loss: 0.0005667898803949356 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 235/5890  Current Loss: 0.0005732104764319956 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 235/5900  Current Loss: 0.0006290443707257509 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 236/5910  Current Loss: 0.0007987692370079458 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 236/5920  Current Loss: 0.0038472891319543123 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 237/5930  Current Loss: 0.0014632458332926035 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 237/5940  Current Loss: 0.00130635523237288 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 237/5950  Current Loss: 0.000731077918317169 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 238/5960  Current Loss: 0.0010206089355051517 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 238/5970  Current Loss: 0.000905423192307353 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 239/5980  Current Loss: 0.0008298574248328805 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 239/5990  Current Loss: 0.0011046858271583915 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 239/6000  Current Loss: 0.0010103161912411451 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 240/6010  Current Loss: 0.0006516561261378229 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 240/6020  Current Loss: 0.0006245584809221327 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 241/6030  Current Loss: 0.0008301216294057667 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 241/6040  Current Loss: 0.0005527497851289809 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 241/6050  Current Loss: 0.0005500923725776374 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 242/6060  Current Loss: 0.0006041476735845208 and previously recorded Min Loss 0.0005463252309709787\n",
      "Iteration: 242/6070  Current Loss: 0.0005457107909023762 and previously recorded Min Loss 0.0005463252309709787\n",
      " Model saved\n",
      "Iteration: 243/6080  Current Loss: 0.0005301220226101577 and previously recorded Min Loss 0.0005457107909023762\n",
      " Model saved\n",
      "Iteration: 243/6090  Current Loss: 0.0005903629935346544 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 243/6100  Current Loss: 0.0006727287545800209 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 244/6110  Current Loss: 0.0006123219500295818 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 244/6120  Current Loss: 0.0005360827199183404 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 245/6130  Current Loss: 0.0005389742436818779 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 245/6140  Current Loss: 0.0005597455310635269 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 245/6150  Current Loss: 0.0005615537520498037 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 246/6160  Current Loss: 0.000583366141654551 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 246/6170  Current Loss: 0.0005462603876367211 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 247/6180  Current Loss: 0.0005550820496864617 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 247/6190  Current Loss: 0.0005778000922873616 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 247/6200  Current Loss: 0.0005303679499775171 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 248/6210  Current Loss: 0.0005974520463496447 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 248/6220  Current Loss: 0.0006846874603070319 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 249/6230  Current Loss: 0.0005429413286037743 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 249/6240  Current Loss: 0.000598651822656393 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 249/6250  Current Loss: 0.0005318991024978459 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 250/6260  Current Loss: 0.0005468472954817116 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 250/6270  Current Loss: 0.0005483293207362294 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 251/6280  Current Loss: 0.0005609600339084864 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 251/6290  Current Loss: 0.0005767253460362554 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 251/6300  Current Loss: 0.0005396770429797471 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 252/6310  Current Loss: 0.0005684089264832437 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 252/6320  Current Loss: 0.0006159529439173639 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 253/6330  Current Loss: 0.0005422431277111173 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 253/6340  Current Loss: 0.00060627656057477 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 253/6350  Current Loss: 0.000558001920580864 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 254/6360  Current Loss: 0.0005313924048095942 and previously recorded Min Loss 0.0005301220226101577\n",
      "Iteration: 254/6370  Current Loss: 0.0005274838767945766 and previously recorded Min Loss 0.0005301220226101577\n",
      " Model saved\n",
      "Iteration: 255/6380  Current Loss: 0.0006637119222432375 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 255/6390  Current Loss: 0.0005708826938644052 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 255/6400  Current Loss: 0.0006702671525999904 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 256/6410  Current Loss: 0.0005533703952096403 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 256/6420  Current Loss: 0.0005491409683600068 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 257/6430  Current Loss: 0.0008042976842261851 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 257/6440  Current Loss: 0.0006050640367902815 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 257/6450  Current Loss: 0.0005878061056137085 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 258/6460  Current Loss: 0.0007028684485703707 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 258/6470  Current Loss: 0.0006094726850278676 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 259/6480  Current Loss: 0.0006159986951388419 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 259/6490  Current Loss: 0.0005678809829987586 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 259/6500  Current Loss: 0.0005695375730283558 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 260/6510  Current Loss: 0.0005882796831429005 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 260/6520  Current Loss: 0.000614331744145602 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 261/6530  Current Loss: 0.0006079585873521864 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 261/6540  Current Loss: 0.0006282618269324303 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 261/6550  Current Loss: 0.0005932720378041267 and previously recorded Min Loss 0.0005274838767945766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 262/6560  Current Loss: 0.0006017292616888881 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 262/6570  Current Loss: 0.0006544273346662521 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 263/6580  Current Loss: 0.0006643887609243393 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 263/6590  Current Loss: 0.0009533859556540847 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 263/6600  Current Loss: 0.0006181666976772249 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 264/6610  Current Loss: 0.0006558336317539215 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 264/6620  Current Loss: 0.0006445302860811353 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 265/6630  Current Loss: 0.0006023505120538175 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 265/6640  Current Loss: 0.0005458580562844872 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 265/6650  Current Loss: 0.0006465435726568103 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 266/6660  Current Loss: 0.0006418342818506062 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 266/6670  Current Loss: 0.001121813664212823 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 267/6680  Current Loss: 0.001146480324678123 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 267/6690  Current Loss: 0.0006992921698838472 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 267/6700  Current Loss: 0.000763801159337163 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 268/6710  Current Loss: 0.000694836606271565 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 268/6720  Current Loss: 0.0005394291365519166 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 269/6730  Current Loss: 0.0005802543018944561 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 269/6740  Current Loss: 0.0005554558010771871 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 269/6750  Current Loss: 0.0006030747899785638 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 270/6760  Current Loss: 0.0005431304452940822 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 270/6770  Current Loss: 0.0005869069718755782 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 271/6780  Current Loss: 0.0005436319042928517 and previously recorded Min Loss 0.0005274838767945766\n",
      "Iteration: 271/6790  Current Loss: 0.000523208174854517 and previously recorded Min Loss 0.0005274838767945766\n",
      " Model saved\n",
      "Iteration: 271/6800  Current Loss: 0.0006761400727555156 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 272/6810  Current Loss: 0.0005709241377189755 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 272/6820  Current Loss: 0.0005373063613660634 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 273/6830  Current Loss: 0.0005280228215269744 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 273/6840  Current Loss: 0.0006006376934237778 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 273/6850  Current Loss: 0.0005407732678577304 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 274/6860  Current Loss: 0.0005965852178633213 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 274/6870  Current Loss: 0.000734336965251714 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 275/6880  Current Loss: 0.000573170545976609 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 275/6890  Current Loss: 0.0005631813546642661 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 275/6900  Current Loss: 0.0007193180499598384 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 276/6910  Current Loss: 0.0007595467614009976 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 276/6920  Current Loss: 0.0007235812954604626 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 277/6930  Current Loss: 0.0011585841421037912 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 277/6940  Current Loss: 0.0009574063587933779 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 277/6950  Current Loss: 0.0006453595706261694 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 278/6960  Current Loss: 0.0008850560989230871 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 278/6970  Current Loss: 0.0007028295658528805 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 279/6980  Current Loss: 0.000706641876604408 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 279/6990  Current Loss: 0.0006481997552327812 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 279/7000  Current Loss: 0.0005664982018060982 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 280/7010  Current Loss: 0.0007328203646466136 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 280/7020  Current Loss: 0.0007256855606101453 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 281/7030  Current Loss: 0.0013450667029246688 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 281/7040  Current Loss: 0.0006882314919494092 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 281/7050  Current Loss: 0.000579866289626807 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 282/7060  Current Loss: 0.000595671299379319 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 282/7070  Current Loss: 0.000536450301297009 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 283/7080  Current Loss: 0.0005355813191272318 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 283/7090  Current Loss: 0.0005342128570191562 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 283/7100  Current Loss: 0.0006300411187112331 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 284/7110  Current Loss: 0.000589866132941097 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 284/7120  Current Loss: 0.0005710967816412449 and previously recorded Min Loss 0.000523208174854517\n",
      "Iteration: 285/7130  Current Loss: 0.000519965251442045 and previously recorded Min Loss 0.000523208174854517\n",
      " Model saved\n",
      "Iteration: 285/7140  Current Loss: 0.000559905543923378 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 285/7150  Current Loss: 0.0005375571781769395 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 286/7160  Current Loss: 0.0006105172797106206 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 286/7170  Current Loss: 0.0005850448505952954 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 287/7180  Current Loss: 0.0005670063546858728 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 287/7190  Current Loss: 0.0005390305304899812 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 287/7200  Current Loss: 0.0006545929936692119 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 288/7210  Current Loss: 0.0005846491549164057 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 288/7220  Current Loss: 0.0005531103233806789 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 289/7230  Current Loss: 0.000564360583666712 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 289/7240  Current Loss: 0.0005410502781160176 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 289/7250  Current Loss: 0.0006788520840927958 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 290/7260  Current Loss: 0.0005678713787347078 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 290/7270  Current Loss: 0.0006044607725925744 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 291/7280  Current Loss: 0.0005752771394327283 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 291/7290  Current Loss: 0.000562783912755549 and previously recorded Min Loss 0.000519965251442045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 291/7300  Current Loss: 0.000607899681199342 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 292/7310  Current Loss: 0.000630547699984163 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 292/7320  Current Loss: 0.0010171668836846948 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 293/7330  Current Loss: 0.000757844012696296 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 293/7340  Current Loss: 0.000707702711224556 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 293/7350  Current Loss: 0.0006059124716557562 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 294/7360  Current Loss: 0.0006624383386224508 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 294/7370  Current Loss: 0.000703182362485677 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 295/7380  Current Loss: 0.0005659142625518143 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 295/7390  Current Loss: 0.0007395705906674266 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 295/7400  Current Loss: 0.0007131315651349723 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 296/7410  Current Loss: 0.0006382772116921842 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 296/7420  Current Loss: 0.0005825809785164893 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 297/7430  Current Loss: 0.0006618883926421404 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 297/7440  Current Loss: 0.0006334458594210446 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 297/7450  Current Loss: 0.0015082766767591238 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 298/7460  Current Loss: 0.0016328247729688883 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 298/7470  Current Loss: 0.0008495426154695451 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 299/7480  Current Loss: 0.0012711909366771579 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 299/7490  Current Loss: 0.0011272707488387823 and previously recorded Min Loss 0.000519965251442045\n",
      "Iteration: 299/7500  Current Loss: 0.0011677095899358392 and previously recorded Min Loss 0.000519965251442045\n",
      "Minimum loss 0.000519965251442045\n",
      "Total Learning time 588.7998803, Learning time without validation 323.61062579998713, Average Learning time 1.1343759833332892\n",
      "Model took 632.9810190999999 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "print(config.X_train_path_single)\n",
    "X_train_org = pickle.load(open(config.X_train_path_single, 'rb'))\n",
    "X_train, X_valid = run_model.train_test_split(X_train_org, test_size=0.2, random_state=42, shuffle=True)  # Split the set\n",
    "print(len(X_train))\n",
    "# running model\n",
    "tic = time.perf_counter()\n",
    "run_model.main(np.array(X_train), np.array(X_valid), config.fp)\n",
    "toc = time.perf_counter()\n",
    "print(\"Model took {} seconds\".format((toc - tic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for v_0.78_\n",
      "Model loaded successfully\n",
      "Running tensormaker\n",
      "Test Input Data Transformed\n",
      "Test Target Data Transformed\n",
      "Starting files set v_0.78_\n",
      "X file v_0.78_test.pk\n",
      " Model saved\n",
      "Model from v_0.78_, Test data v_0.78_, Loss: 0.0005367662524804473 \n"
     ]
    }
   ],
   "source": [
    "# Testing Model\n",
    "combined_setup_list = [config.fp]\n",
    "exp_name_list = [config.fp]\n",
    "for i in range(len(exp_name_list)):\n",
    "    print('Running for {}'.format(exp_name_list[i]))\n",
    "    chkpoint_filename = config.model_chkpnt_path + combined_setup_list[i] + 'model_min_loss.ckpt'\n",
    "    std_scalar_filename = config.model_chkpnt_path + combined_setup_list[i] + 'std_scaler_train.pk'\n",
    "    std_y_filename = config.model_chkpnt_path + combined_setup_list[i] + 'sc_y_train.pk'\n",
    "    training_time_filename = config.model_chkpnt_path + combined_setup_list[i] + 'training_time.pk'\n",
    "    exp_name=exp_name_list[i]\n",
    "    predict_from_chkpnt.predict_from_chkpnt(chkpoint_filename, std_scalar_filename, std_y_filename, exp_name, training_time_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std error 12.018173633360641, mean error 0.1722536128016949, mse 0.00014446616878872816, errors_percentage 1.1592664869331817\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "# reading processed data\n",
    "labels = pickle.load(open(config.label_file, 'rb')).flatten()\n",
    "outputs = pickle.load(open(config.output_file, 'rb')).flatten()\n",
    "errors = labels - outputs\n",
    "sigma = np.std(errors) * 1000  # ns to ps\n",
    "mu = np.ndarray.mean(errors) * 1000  # ns to ps\n",
    "errors_percentage = (np.std(errors) / max(labels)) * 100\n",
    "mse = np.square(np.subtract(labels,outputs)).mean()\n",
    "print('Std error {}, mean error {}, mse {}, errors_percentage {}'.format(sigma, mu, mse, errors_percentage))\n",
    "filename = config.model_chkpnt_path+config.fp\n",
    "utility.save_as_csv(labels, outputs, errors, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CAD]",
   "language": "python",
   "name": "conda-env-CAD-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
